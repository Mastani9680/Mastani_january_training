# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vX0T_aINA-HJhY4W4MhlIUcKpTLnC24s
"""

from google.colab import files

# This will open a file chooser
uploaded = files.upload()

import pandas as pd

df = pd.read_csv('Life Expectancy Data.csv')
df.head()

import pandas as pd

df = pd.read_csv('Life Expectancy Data.csv')
df.head()
df.info()

print(df.isnull().sum())

import pandas as pd

# Load the dataset
<<<<<<< HEAD
df = pd.read_csv('Life Expectancy Data.csv') 
=======
df = pd.read_csv('Life Expectancy Data.csv')  # replace with your CSV file name
>>>>>>> b0abdbbb1ca7fd8a1eec670ba4d0e7ff26edf467

#  Handle numeric columns (float/int) â†’ fill with median
numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
for col in numeric_cols:
    df[col] = df[col].fillna(df[col].median())
#mode
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    df[col] = df[col].fillna(df[col].mode()[0])
print(df.isnull().sum())

import pandas as pd

# Load dataset
df = pd.read_csv('Life Expectancy Data.csv')

# Check data types
print(df.dtypes)

import pandas as pd
import numpy as np
df = pd.read_csv('Life Expectancy Data.csv')
numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
#detect outliers
def detect_outliers(col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    outliers = df[(df[col] < lower) | (df[col] > upper)]
    print(f"{col}: {len(outliers)} outliers")
# Detect outliers in all numeric columns
for col in numeric_cols:
    detect_outliers(col)

import pandas as pd
df = pd.read_csv('Life Expectancy Data.csv')
# Check number of duplicate rows
num_duplicates = df.duplicated().sum()
print(f"Number of duplicate rows: {num_duplicates}")

import pandas as pd
df = pd.read_csv('Life Expectancy Data.csv')
# Clean column names (remove spaces)
df.columns = df.columns.str.strip().str.replace(' ', '_').str.lower()
# List of irrelevant columns
irrelevant_cols = ['country', 'year']
# Drop irrelevant columns
df = df.drop(columns=irrelevant_cols)
# Verify remaining columns
<<<<<<< HEAD
print("Remaining columns:", df.columns)
=======
print("Remaining columns:", df.columns)
>>>>>>> b0abdbbb1ca7fd8a1eec670ba4d0e7ff26edf467
